{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from unidecode import unidecode\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry helpers to test simplification\n",
    "def get_num_coords(poly):\n",
    "    return len(poly.exterior.coords)\n",
    "\n",
    "def get_total_num_coords(geom):\n",
    "    if geom.geom_type == 'MultiPolygon':\n",
    "        return sum(get_num_coords(poly) for poly in geom)\n",
    "    elif geom.geom_type == 'Polygon':\n",
    "        return get_num_coords(geom)\n",
    "    else:\n",
    "        raise ValueError('Geometry type must be either \"Polygon\" or \"MultiPolygon\"')\n",
    "\n",
    "def get_pg_engine():\n",
    "    connection_string = 'postgresql://{user}:{password}@{host}:{port}/{db}'.format(\n",
    "        user=os.environ['PG_USER'],\n",
    "        password=os.environ['PG_PASSWORD'],\n",
    "        host=os.environ['PG_HOST'],\n",
    "        port=os.environ['PG_PORT'],\n",
    "        db=os.environ['PG_DATABASE']\n",
    "    )\n",
    "    \n",
    "    return create_engine(connection_string)\n",
    "\n",
    "\n",
    "def format_column(column_name):\n",
    "    \"\"\"Format a column name to be a valid BigQuery identifier\"\"\"\n",
    "    chars_to_remove = \"¿?(),.\"\n",
    "    chars_to_replace = {\"/\": \"_\", \" \": \"_\", \"%\": \"pct\"}\n",
    "    for char in chars_to_remove:\n",
    "        column_name = column_name.replace(char, \"\")\n",
    "    for original_char, new_char in chars_to_replace.items():\n",
    "        column_name = column_name.replace(original_char, new_char)\n",
    "        \n",
    "    # Multiple underscores into a single one\n",
    "    column_name = '_'.join([part for part in column_name.split('_') if part != ''])\n",
    "\n",
    "    column_name = unidecode(column_name.lower())\n",
    "    return column_name\n",
    "\n",
    "\n",
    "def gdf_from_df(df):\n",
    "    \"\"\"Construct a GeoDataFrame from a Pandas' DataFrame\n",
    "    \n",
    "    Assume the original DataFrame contains point information\n",
    "    in fields `latitude` and `longitude`\"\"\"\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude']))\n",
    "    gdf = gdf.drop(columns=['latitude', 'longitude'])\n",
    "    gdf = gdf.set_crs(epsg=4326)\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def fetch_camps_data():\n",
    "    gspread_client = gspread.service_account('../campateca/campateca_sheets_service_account.json')\n",
    "\n",
    "    sheet = gspread_client.open_by_key(os.environ['CAMPATECA_SHEET_ID']).worksheet('campateca')\n",
    "    df = pd.DataFrame(sheet.get_all_records())\n",
    "    df = df.replace({'': None, '#N/A': None})\n",
    "    df.columns = df.columns.map(format_column)\n",
    "\n",
    "    cols_to_drop = ['base_de_datos', 'como_contactar_quien_y_como', 'info_pleyades_hemos_llamado_visitado_cuando']\n",
    "    cols_to_rename = {\n",
    "        'si_has_estado_valora_el_campa_del_1_al_5': 'valoracion',\n",
    "        'con_cuantas_plazas': 'num_plazas_cabanas_habitaciones',\n",
    "        'breve_descripcion_info_adicional_ej_mola_para_rutas': 'comentarios',\n",
    "    }\n",
    "    boolean_cols = ['agua_corriente', 'electricidad', 'aseos', 'cocina', 'comedor', 'cabanas_habitaciones']\n",
    "\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "    df = df.rename(columns=cols_to_rename)\n",
    "    \n",
    "    # Drop empty rows\n",
    "    df = df.loc[df['municipio'].notnull()]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def upload_table_create_view(gdf, table_name):\n",
    "    view_name = f'{table_name}_geojson'\n",
    "    conn.execute(f'DROP VIEW IF EXISTS {view_name}')\n",
    "    gdf.to_postgis(table_name, conn, if_exists='replace')\n",
    "    view_q = \"\"\"\n",
    "    CREATE OR REPLACE VIEW {table_name}_geojson AS (\n",
    "      SELECT\n",
    "        json_build_object(\n",
    "          'type', 'FeatureCollection',\n",
    "          'features', json_agg(ST_AsGeoJSON(c.*)::json)\n",
    "        ) AS geojson\n",
    "      FROM {table_name} c\n",
    "    )\"\"\"\n",
    "    \n",
    "    conn.execute(view_q.format(table_name=table_name))\n",
    "\n",
    "\n",
    "pg_engine = get_pg_engine()\n",
    "conn = pg_engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_camps_data()\n",
    "gdf = gdf_from_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-ghana",
   "metadata": {},
   "source": [
    "Write file locally as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('campas.geojson', 'w') as fp:\n",
    "    fp.write(gdf.loc[:40].to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-payment",
   "metadata": {},
   "source": [
    "Upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_table_create_view(gdf, 'campamentos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-serial",
   "metadata": {},
   "source": [
    "## Cuencas hidrográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuencas_cols = ['localId', 'nameText', 'rbdName', 'rbdArea', 'rbdAreaExc', 'internatio', 'interName', 'versionId', 'geometry']\n",
    "cuencas_rename = {\n",
    "    'localId': 'id',\n",
    "    'nameText': 'name_esp',\n",
    "    'rbdName': 'name_eng',\n",
    "    'rbdArea': 'area',\n",
    "    'rbdAreaExc': 'area_exc',\n",
    "    'internatio': 'international',\n",
    "    'interName': 'name_international',\n",
    "    'versionId': 'version',\n",
    "}\n",
    "\n",
    "cuencas = gpd.read_file('data/demarcaciones_hidograficas/')[cuencas_cols]\n",
    "cuencas = cuencas.rename(columns=cuencas_rename)\n",
    "\n",
    "cuencas = cuencas.to_crs(epsg=4326)\n",
    "\n",
    "cuencas.geometry = cuencas.geometry.simplify(0.001) # Good simplification without looking ugly\n",
    "\n",
    "upload_table_create_view(cuencas, 'cuencas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-chester",
   "metadata": {},
   "source": [
    "## Comunidades Autónomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefiles = {\n",
    "    'peninbal': 'data/SHP_ETRS89/recintos_autonomicas_inspire_peninbal_etrs89/',\n",
    "    'canarias': 'data/SHP_WGS84/recintos_autonomicas_inspire_canarias_wgs84/'\n",
    "}\n",
    "\n",
    "gdfs = []\n",
    "for fp in shapefiles.values():\n",
    "    gdf = gpd.read_file(fp)\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    gdfs.append(gdf)\n",
    "\n",
    "gdf = pd.concat(gdfs, ignore_index=True)\n",
    "gdf.geometry = gdf.geometry.simplify(0.001)\n",
    "\n",
    "upload_table_create_view(gdf, 'ccaa')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
